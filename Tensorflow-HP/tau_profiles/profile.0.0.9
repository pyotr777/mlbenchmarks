8 templated_functions_MULTI_TAUGPU_TIME
# Name Calls Subrs Excl Incl ProfileCalls # <metadata><attribute><name>Metric Name</name><value>TAUGPU_TIME</value></attribute><attribute><name>CPU Cores</name><value>8</value></attribute><attribute><name>CPU MHz</name><value>2701.242</value></attribute><attribute><name>CPU Type</name><value>Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</value></attribute><attribute><name>CPU Vendor</name><value>GenuineIntel</value></attribute><attribute><name>CWD</name><value>/home/ubuntu/benchmarks/scripts/tf_cnn_benchmarks</value></attribute><attribute><name>Cache Size</name><value>46080 KB</value></attribute><attribute><name>Command Line</name><value>python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=32 --model=resnet50 --num_batches=3 --num_warmup_batches=1</value></attribute><attribute><name>Ending Timestamp</name><value>1513566154202703</value></attribute><attribute><name>Executable</name><value>/usr/bin/python2.7</value></attribute><attribute><name>GPU Name</name><value>Tesla M60</value></attribute><attribute><name>GPU computeCapabilityMajor</name><value>5</value></attribute><attribute><name>GPU computeCapabilityMinor</name><value>2</value></attribute><attribute><name>GPU constantMemorySize</name><value>65536</value></attribute><attribute><name>GPU coreClockRate</name><value>1177500</value></attribute><attribute><name>GPU globalMemoryBandwidth</name><value>160320000</value></attribute><attribute><name>GPU globalMemorySize</name><value>7983005696</value></attribute><attribute><name>GPU l2CacheSize</name><value>2097152</value></attribute><attribute><name>GPU maxBlocksPerMultiprocessor</name><value>32</value></attribute><attribute><name>GPU maxIPC</name><value>6</value></attribute><attribute><name>GPU maxRegistersPerBlock</name><value>65536</value></attribute><attribute><name>GPU maxSharedMemoryPerBlock</name><value>49152</value></attribute><attribute><name>GPU maxThreadsPerBlock</name><value>1024</value></attribute><attribute><name>GPU maxWarpsPerMultiprocessor</name><value>64</value></attribute><attribute><name>GPU numMemcpyEngines</name><value>2</value></attribute><attribute><name>GPU numMultiprocessors</name><value>16</value></attribute><attribute><name>GPU numThreadsPerWarp</name><value>32</value></attribute><attribute><name>Hostname</name><value>ip-172-31-59-213</value></attribute><attribute><name>Local Time</name><value>2017-12-18T03:02:03+00:00</value></attribute><attribute><name>Memory Size</name><value>125827876 kB</value></attribute><attribute><name>Node Name</name><value>ip-172-31-59-213</value></attribute><attribute><name>OMP_CHUNK_SIZE</name><value>1</value></attribute><attribute><name>OMP_DYNAMIC</name><value>off</value></attribute><attribute><name>OMP_MAX_THREADS</name><value>16</value></attribute><attribute><name>OMP_NESTED</name><value>off</value></attribute><attribute><name>OMP_NUM_PROCS</name><value>16</value></attribute><attribute><name>OMP_SCHEDULE</name><value>UNKNOWN</value></attribute><attribute><name>OS Machine</name><value>x86_64</value></attribute><attribute><name>OS Name</name><value>Linux</value></attribute><attribute><name>OS Release</name><value>4.4.0-1041-aws</value></attribute><attribute><name>OS Version</name><value>#50-Ubuntu SMP Wed Nov 15 22:18:17 UTC 2017</value></attribute><attribute><name>Starting Timestamp</name><value>1513566121634647</value></attribute><attribute><name>TAU Architecture</name><value>default</value></attribute><attribute><name>TAU Config</name><value> -arch=x86_64 -prefix=/home/ubuntu/TAU -openmp -cuda=/usr/local/cuda -bfd=download</value></attribute><attribute><name>TAU Makefile</name><value>/home/ubuntu/TAU/x86_64/lib/Makefile.tau-cupti-openmp</value></attribute><attribute><name>TAU Version</name><value>2.27-git</value></attribute><attribute><name>TAU_BFD_LOOKUP</name><value>on</value></attribute><attribute><name>TAU_CALLPATH</name><value>off</value></attribute><attribute><name>TAU_CALLPATH_DEPTH</name><value>2</value></attribute><attribute><name>TAU_CALLSITE_DEPTH</name><value>1</value></attribute><attribute><name>TAU_COMPENSATE</name><value>off</value></attribute><attribute><name>TAU_CUDA_BINARY_EXE</name><value></value></attribute><attribute><name>TAU_CUPTI_API</name><value>runtime</value></attribute><attribute><name>TAU_EBS_KEEP_UNRESOLVED_ADDR</name><value>off</value></attribute><attribute><name>TAU_IBM_BG_HWP_COUNTERS</name><value>off</value></attribute><attribute><name>TAU_MAX_THREADS</name><value>128</value></attribute><attribute><name>TAU_MEASURE_TAU</name><value>off</value></attribute><attribute><name>TAU_MEMDBG_PROTECT_ABOVE</name><value>off</value></attribute><attribute><name>TAU_MEMDBG_PROTECT_BELOW</name><value>off</value></attribute><attribute><name>TAU_MEMDBG_PROTECT_FREE</name><value>off</value></attribute><attribute><name>TAU_OPENMP_RUNTIME</name><value>on</value></attribute><attribute><name>TAU_OPENMP_RUNTIME_EVENTS</name><value>on</value></attribute><attribute><name>TAU_OPENMP_RUNTIME_STATES</name><value>off</value></attribute><attribute><name>TAU_OUTPUT_CUDA_CSV</name><value>off</value></attribute><attribute><name>TAU_PAPI_MULTIPLEXING</name><value>off</value></attribute><attribute><name>TAU_PROFILE</name><value>on</value></attribute><attribute><name>TAU_PROFILE_FORMAT</name><value>profile</value></attribute><attribute><name>TAU_SAMPLING</name><value>off</value></attribute><attribute><name>TAU_SHOW_MEMORY_FUNCTIONS</name><value>off</value></attribute><attribute><name>TAU_SIGNALS_GDB</name><value>off</value></attribute><attribute><name>TAU_THROTTLE</name><value>on</value></attribute><attribute><name>TAU_THROTTLE_NUMCALLS</name><value>100000</value></attribute><attribute><name>TAU_THROTTLE_PERCALL</name><value>10</value></attribute><attribute><name>TAU_TRACE</name><value>off</value></attribute><attribute><name>TAU_TRACE_FORMAT</name><value>tau</value></attribute><attribute><name>TAU_TRACK_CUDA_CDP</name><value>off</value></attribute><attribute><name>TAU_TRACK_CUDA_INSTRUCTIONS</name><value></value></attribute><attribute><name>TAU_TRACK_CUDA_SASS</name><value>off</value></attribute><attribute><name>TAU_TRACK_HEADROOM</name><value>off</value></attribute><attribute><name>TAU_TRACK_HEAP</name><value>on</value></attribute><attribute><name>TAU_TRACK_IO_PARAMS</name><value>off</value></attribute><attribute><name>TAU_TRACK_MEMORY_FOOTPRINT</name><value>off</value></attribute><attribute><name>TAU_TRACK_MEMORY_LEAKS</name><value>on</value></attribute><attribute><name>TAU_TRACK_SIGNALS</name><value>off</value></attribute><attribute><name>TAU_TRACK_UNIFIED_MEMORY</name><value>off</value></attribute><attribute><name>Timestamp</name><value>1513566123418595</value></attribute><attribute><name>UTC Time</name><value>2017-12-18T03:02:03Z</value></attribute><attribute><name>pid</name><value>74581</value></attribute><attribute><name>tid</name><value>74581</value></attribute><attribute><name>username</name><value>ubuntu</value></attribute></metadata>
".TAU application" 1 15 232037 240534.25 0 GROUP="TAU_USER" 
"void fft2d_r2c_32x32<float, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)" 2 0 338.75 338.75 0 GROUP="TAU_USER" 
"void fft2d_c2r_32x32<float, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)" 2 0 527.5 527.5 0 GROUP="TAU_USER" 
"void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)" 3 0 1841 1841 0 GROUP="TAU_USER" 
"cudnn_maxwell_gcgemm_32x32_nt_batched" 1 0 1132.25 1132.25 0 GROUP="TAU_USER" 
"void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)" 3 0 2702.5 2702.5 0 GROUP="TAU_USER" 
"cudnn_maxwell_cgemm_64x32_nt_batched" 2 0 587.75 587.75 0 GROUP="TAU_USER" 
"cudnn_maxwell_cgemm_32x64_nt_batched" 2 0 1367.5 1367.5 0 GROUP="TAU_USER" 
0 aggregates
18 userevents
# eventname numevents max min mean sumsqr
"Allocatable Blocks per SM given Thread count (Blocks)" 15 32 4 20.26666666666667 8256
"Allocatable Blocks Per SM given Registers used (Blocks)" 15 5 2 3.666666666666667 219
"Allocatable Blocks Per SM given Shared Memory usage (Blocks)" 15 1024 4 278.8 4195110
"GPU Occupancy (Warps)" 15 32 4 15.13333333333333 5307
"Block Size" 15 512 32 187.7333333333333 1124352
"Shared Dynamic Memory (bytes)" 15 35904 0 9574.4 5156388864
"Shared Static Memory (bytes)" 15 12288 0 5836.8 868614144
"Local Memory (bytes per thread)" 15 0 0 0 0
"Local Registers (per thread)" 15 124 64 91.46666666666667 131184
"Block Size : void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)" 15 512 32 187.7333333333333 1124352
"Shared Dynamic Memory (bytes) : void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)" 15 35904 0 9574.4 5156388864
"Shared Static Memory (bytes) : void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)" 15 12288 0 5836.8 868614144
"Local Memory (bytes per thread) : void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)" 15 0 0 0 0
"Local Registers (per thread) : void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)" 15 124 64 91.46666666666667 131184
"Allocatable Blocks Per SM given Shared Memory usage (Blocks) : void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)" 15 1024 4 278.8 4195110
"GPU Occupancy (Warps) : void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)" 15 32 4 15.13333333333333 5307
"Allocatable Blocks per SM given Thread count (Blocks) : void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)" 15 32 4 20.26666666666667 8256
"Allocatable Blocks Per SM given Registers used (Blocks) : void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)" 15 5 2 3.666666666666667 219
